{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDXQjIb88cLF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mM6BlD2Z8dA-"
   },
   "outputs": [],
   "source": [
    "hotels = pd.read_csv('task_data/data/hotels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NlOw7JUzMOm_"
   },
   "outputs": [],
   "source": [
    "hotels_test = pd.read_csv('task_data/data/hotels_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "IFjH0e1c83R3",
    "outputId": "1cb0b405-eb4f-4132-fd8d-3cf5076603be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nxdd9sN7Fi58c_h3iKDyJg</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JEs3sXyQu2GlP_aooyymZw</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okIjifZcimFjXoXGPJd38w</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zsSGQz1EAxrnQ9xMCUCowA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gP_6kJb2JSI3vPjCK2alVA</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_id  stars\n",
       "0  nxdd9sN7Fi58c_h3iKDyJg    3.5\n",
       "1  JEs3sXyQu2GlP_aooyymZw    3.5\n",
       "2  okIjifZcimFjXoXGPJd38w    3.5\n",
       "3  zsSGQz1EAxrnQ9xMCUCowA    5.0\n",
       "4  gP_6kJb2JSI3vPjCK2alVA    3.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "9u0ZpVMr9MlI",
    "outputId": "ad791cf3-2560-459b-ca67-b4f8e0d228f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим сколько всего у нас классов\n",
    "labels = hotels.stars.values\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "NuP3tUfi9Pjv",
    "outputId": "5a300d9d-1e74-427c-a9ea-fa894695f702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "nacEMzHK9SqK",
    "outputId": "905fe3ea-104c-4ff3-a323-f78bb8b6b301"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awgoBwuhzlLGKEIverTGjQ</td>\n",
       "      <td>yyPHK6khPa4-ErV9U32x3A</td>\n",
       "      <td>Best location ever! I love love love the manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pR9HHzbUdZ0Gt80_3NmmQw</td>\n",
       "      <td>Yy_iGXxLpL6tYDQoE-6XVg</td>\n",
       "      <td>I'm not good at explaining how I want my hair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ex1-tKlQa74J0usZVHxYEw</td>\n",
       "      <td>OQT9DjfBrzrwOEdVJjuYIA</td>\n",
       "      <td>Hands down this place offers the BEST children...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kvr3maTyGSS9Xo_nhsEvrA</td>\n",
       "      <td>FHwl6kaKdD5-KAnfVb_pKQ</td>\n",
       "      <td>Good local shop.  I haven't experienced any ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2Ezp_HYCIVE-h7hpBBvtxw</td>\n",
       "      <td>AlzerMK7z84E4KU6GjPzIQ</td>\n",
       "      <td>I rarely give out 5 stars. It has to be incred...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_id                 user_id  \\\n",
       "0  awgoBwuhzlLGKEIverTGjQ  yyPHK6khPa4-ErV9U32x3A   \n",
       "1  pR9HHzbUdZ0Gt80_3NmmQw  Yy_iGXxLpL6tYDQoE-6XVg   \n",
       "2  Ex1-tKlQa74J0usZVHxYEw  OQT9DjfBrzrwOEdVJjuYIA   \n",
       "3  Kvr3maTyGSS9Xo_nhsEvrA  FHwl6kaKdD5-KAnfVb_pKQ   \n",
       "4  2Ezp_HYCIVE-h7hpBBvtxw  AlzerMK7z84E4KU6GjPzIQ   \n",
       "\n",
       "                                                text  \n",
       "0  Best location ever! I love love love the manag...  \n",
       "1  I'm not good at explaining how I want my hair ...  \n",
       "2  Hands down this place offers the BEST children...  \n",
       "3  Good local shop.  I haven't experienced any ra...  \n",
       "4  I rarely give out 5 stars. It has to be incred...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('task_data/data/reviews_train.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbMvc5SaMWXf"
   },
   "outputs": [],
   "source": [
    "reviews_test = pd.read_csv('task_data/data/reviews_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "CqIjRAvN9UpW",
    "outputId": "07e4d01e-7aa9-473a-ec01-9dfe563c03cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27789</th>\n",
       "      <td>1OXw5J-nW8se7tPFgyYu3w</td>\n",
       "      <td>ZSjYiQPN2OjA1qg8Hp0_RQ</td>\n",
       "      <td>Fab Fern photo booth was at my wedding in Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27790</th>\n",
       "      <td>K0fhZVoUMY0JaYuMGoMP-A</td>\n",
       "      <td>DE7L3LlEXBTRyYlLLvb1vA</td>\n",
       "      <td>I'd heard about colon hydrotherapy from watchi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27791</th>\n",
       "      <td>lY2RT75tYZCb2YHWu3bbNQ</td>\n",
       "      <td>7U3H1iJZ04FbadJtt2Npjg</td>\n",
       "      <td>I love the location. It's tucked away and not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27792</th>\n",
       "      <td>wXqIh5t-VjN6-jHz6XMXDQ</td>\n",
       "      <td>pJ1spPyqGHDiLR_yTCl-qA</td>\n",
       "      <td>My experience here was absolutely amazing. I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27793</th>\n",
       "      <td>LrBCULmDal38G7-UdGM7zA</td>\n",
       "      <td>ER_ZPy4QoitJK9F0qUY0Bw</td>\n",
       "      <td>My own personal service was fine but the recep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hotel_id                 user_id  \\\n",
       "27789  1OXw5J-nW8se7tPFgyYu3w  ZSjYiQPN2OjA1qg8Hp0_RQ   \n",
       "27790  K0fhZVoUMY0JaYuMGoMP-A  DE7L3LlEXBTRyYlLLvb1vA   \n",
       "27791  lY2RT75tYZCb2YHWu3bbNQ  7U3H1iJZ04FbadJtt2Npjg   \n",
       "27792  wXqIh5t-VjN6-jHz6XMXDQ  pJ1spPyqGHDiLR_yTCl-qA   \n",
       "27793  LrBCULmDal38G7-UdGM7zA  ER_ZPy4QoitJK9F0qUY0Bw   \n",
       "\n",
       "                                                    text  \n",
       "27789  Fab Fern photo booth was at my wedding in Apri...  \n",
       "27790  I'd heard about colon hydrotherapy from watchi...  \n",
       "27791  I love the location. It's tucked away and not ...  \n",
       "27792  My experience here was absolutely amazing. I r...  \n",
       "27793  My own personal service was fine but the recep...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jyy9QrXy9ZZy"
   },
   "source": [
    "Вообще, вещественные метки классов и требование использовать rmse, как бы тонко намекают, что решаем задачу регресси. Но. Классов у нас всего 9. И их можно преобразовать в целое число, домножением на 10. Поэтому будем решать задачу классификации текста.\n",
    "\n",
    "Объединим две таблицы: hotels и reviews, по общему полю - hotel_id. Оставив только отзывы (text) и метку класса(stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "FE3i9Qc29e-x",
    "outputId": "7af446de-12f2-4846-80ed-bd32ccb5a1fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nxdd9sN7Fi58c_h3iKDyJg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>26roJmjRfsPmA9NDQoVrtQ</td>\n",
       "      <td>I have had them for 3 years now. This year the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nxdd9sN7Fi58c_h3iKDyJg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>JjugfnnQ6g44Ztze8j6F1Q</td>\n",
       "      <td>I have been using Lawn Sense for two summers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nxdd9sN7Fi58c_h3iKDyJg</td>\n",
       "      <td>3.5</td>\n",
       "      <td>o-gXSZkYNKmYyNBO_e4XGQ</td>\n",
       "      <td>Zach Livingston from Lawn Sense just treated m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JEs3sXyQu2GlP_aooyymZw</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2EuPAGalYnP7eSxPgFCNDg</td>\n",
       "      <td>Spotted this cute food truck while checking ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JEs3sXyQu2GlP_aooyymZw</td>\n",
       "      <td>3.5</td>\n",
       "      <td>vulPfJ5Q8Hg9nXaKezigfw</td>\n",
       "      <td>I used The Chuck Wagon to cater my events I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_id  stars                 user_id  \\\n",
       "0  nxdd9sN7Fi58c_h3iKDyJg    3.5  26roJmjRfsPmA9NDQoVrtQ   \n",
       "1  nxdd9sN7Fi58c_h3iKDyJg    3.5  JjugfnnQ6g44Ztze8j6F1Q   \n",
       "2  nxdd9sN7Fi58c_h3iKDyJg    3.5  o-gXSZkYNKmYyNBO_e4XGQ   \n",
       "3  JEs3sXyQu2GlP_aooyymZw    3.5  2EuPAGalYnP7eSxPgFCNDg   \n",
       "4  JEs3sXyQu2GlP_aooyymZw    3.5  vulPfJ5Q8Hg9nXaKezigfw   \n",
       "\n",
       "                                                text  \n",
       "0  I have had them for 3 years now. This year the...  \n",
       "1  I have been using Lawn Sense for two summers a...  \n",
       "2  Zach Livingston from Lawn Sense just treated m...  \n",
       "3  Spotted this cute food truck while checking ou...  \n",
       "4  I used The Chuck Wagon to cater my events I ha...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_table = pd.merge(hotels, reviews, how='inner', on=['hotel_id'])\n",
    "temp_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "_FWwP9AT9ftV",
    "outputId": "f536bd34-3b2c-4abc-969c-c90d806f0287"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>I have had them for 3 years now. This year the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>I have been using Lawn Sense for two summers a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>Zach Livingston from Lawn Sense just treated m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>Spotted this cute food truck while checking ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>I used The Chuck Wagon to cater my events I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0    3.5  I have had them for 3 years now. This year the...\n",
       "1    3.5  I have been using Lawn Sense for two summers a...\n",
       "2    3.5  Zach Livingston from Lawn Sense just treated m...\n",
       "3    3.5  Spotted this cute food truck while checking ou...\n",
       "4    3.5  I used The Chuck Wagon to cater my events I ha..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(\n",
    "    {\"text\":pd.Series(temp_table.text), \n",
    "     \"stars\": pd.Series(temp_table.stars)}\n",
    "                  )\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27789</th>\n",
       "      <td>2.5</td>\n",
       "      <td>I went yesterday, on a Thursday evening. It wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27790</th>\n",
       "      <td>2.5</td>\n",
       "      <td>This place used to be really dirty -- I mean t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27791</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Had mixed experiences with this location.  Mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27792</th>\n",
       "      <td>2.5</td>\n",
       "      <td>The worst looking McDonald's in the whole West...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27793</th>\n",
       "      <td>2.5</td>\n",
       "      <td>Dumpy as they go. I've never consistently wait...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stars                                               text\n",
       "27789    2.5  I went yesterday, on a Thursday evening. It wa...\n",
       "27790    2.5  This place used to be really dirty -- I mean t...\n",
       "27791    2.5  Had mixed experiences with this location.  Mos...\n",
       "27792    2.5  The worst looking McDonald's in the whole West...\n",
       "27793    2.5  Dumpy as they go. I've never consistently wait..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем полученные данные в csv. Будем пытаться предсказать stars, считая,\n",
    "# что это метки классов\n",
    "#df.to_csv(file_name, sep='\\t')\n",
    "dataset.to_csv('Review_stars.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nadezhda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подгрузим стоп-слова, если их не было до этого\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nadezhda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import RussianStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление стоп-слов и приведение слов к начальной форме с помощью библиотеки nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "# В дальнейшем хочется использовать n-граммы, поэтому создадим свой словарь стоп-слов(оставим not, no)\n",
    "stop_words = set(['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "                  'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "                  'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "                  'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "                  'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "                  'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "                  'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', \n",
    "                  'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "                  'with', 'about', 'between', 'into', 'through', 'during', \n",
    "                  'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "                  'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', \n",
    "                  'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "                  'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', \n",
    "                  'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', \n",
    "                  't', 'can', 'will', 'just', 'don', 'should', 'now'])\n",
    "\n",
    "def preparation_data(data):\n",
    "    # Разобьем данные на слова\n",
    "    word_tokens = word_tokenize(data) \n",
    "    # Для удаления пунктуации\n",
    "    words = [word.lower() for word in word_tokens if word.isalpha()]\n",
    "    # Сделаем стемминг. Приведем слова к начальной форме, используя lemmatizer и стемминг\n",
    "    wnl = WordNetLemmatizer()\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    words = [stemmer.stem(wnl.lemmatize(word)) for word in words]\n",
    "    #Чтобы в дальннейшем использовать pipeline и n grams, объединим список слов в строку\n",
    "    return ' '.join([word for word in words if not word in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nadezhda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перестроим наш датасет\n",
    "dataset['text'] = dataset['text'].apply(lambda x: preparation_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>[year, year, not, done, done, prior, year, wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5</td>\n",
       "      <td>[using, lawn, sense, two, summer, could, not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>[zach, livingston, lawn, sense, treated, paren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>[spotted, cute, food, truck, checking, car, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>[used, chuck, wagon, cater, event, held, la, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                               text\n",
       "0    3.5  [year, year, not, done, done, prior, year, wee...\n",
       "1    3.5  [using, lawn, sense, two, summer, could, not, ...\n",
       "2    3.5  [zach, livingston, lawn, sense, treated, paren...\n",
       "3    3.5  [spotted, cute, food, truck, checking, car, su...\n",
       "4    3.5  [used, chuck, wagon, cater, event, held, la, v..."
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "dMm9c6m3MgUr",
    "outputId": "a12e90ee-e60e-4293-a6ed-aec92ba5aadd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>Worst limo service ever do not use. Limo was f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>We booked Exotica Limousine Services for our w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>PLEASE READ COMPLETELY BEFORE BOOKING... If yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>This was the worst experience. First off the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>We rented a limo for my friend's 30th birthday...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_id                                               text\n",
       "0  h7j6MJegP80-mCKamFWVng  Worst limo service ever do not use. Limo was f...\n",
       "1  h7j6MJegP80-mCKamFWVng  We booked Exotica Limousine Services for our w...\n",
       "2  h7j6MJegP80-mCKamFWVng  PLEASE READ COMPLETELY BEFORE BOOKING... If yo...\n",
       "3  h7j6MJegP80-mCKamFWVng  This was the worst experience. First off the d...\n",
       "4  h7j6MJegP80-mCKamFWVng  We rented a limo for my friend's 30th birthday..."
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестовые данные\n",
    "temp_table = pd.merge(hotels_test, reviews_test, how='inner', on=['hotel_id'])\n",
    "dataset_test = pd.DataFrame(\n",
    "    {\"hotel_id\":pd.Series(temp_table.hotel_id), \"text\":pd.Series(temp_table.text)}\n",
    "                  )\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем предобработку тестовых данных\n",
    "dataset_test['text'] = dataset_test['text'].apply(lambda x: preparation_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>worst limo service ever not use limo wa filthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>booked exotica limousine service wedding past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>please read completely booking looking pay goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>wa worst experience first driver call repeated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h7j6MJegP80-mCKamFWVng</td>\n",
       "      <td>rented limo friend birthday last night exactly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hotel_id                                               text\n",
       "0  h7j6MJegP80-mCKamFWVng  worst limo service ever not use limo wa filthy...\n",
       "1  h7j6MJegP80-mCKamFWVng  booked exotica limousine service wedding past ...\n",
       "2  h7j6MJegP80-mCKamFWVng  please read completely booking looking pay goo...\n",
       "3  h7j6MJegP80-mCKamFWVng  wa worst experience first driver call repeated...\n",
       "4  h7j6MJegP80-mCKamFWVng  rented limo friend birthday last night exactly..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmvzRU9XGYj7"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4o_aKi9dOdED"
   },
   "source": [
    "Разделим выборку на тренировочную и валидационную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSC-yc4RPbJe"
   },
   "outputs": [],
   "source": [
    "j = np.random.randint(len(dataset))\n",
    "valid_dataset = pd.DataFrame(dataset.iloc[[j]])\n",
    "dataset.drop(dataset.index[j], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAD4H4dJFTcr"
   },
   "outputs": [],
   "source": [
    "# Выберем valid случайно (для воспроизводимости выше зафиксировали random_seed(42))\n",
    "for i in range(7793):\n",
    "    j = np.random.randint(len(dataset))\n",
    "    temp = pd.DataFrame(dataset.iloc[[j]])\n",
    "    valid_dataset = pd.concat([valid_dataset, temp])\n",
    "    dataset.drop(dataset.index[j], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "uMLNEZieVTR-",
    "outputId": "4f12676e-2836-4e52-d961-9794995c573f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>3</td>\n",
       "      <td>realli love busi cute littl store premium pet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>4</td>\n",
       "      <td>not use compani ani busi tax advic wa refer vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2</td>\n",
       "      <td>still understand whi post hour oper anywher ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>3</td>\n",
       "      <td>servic amic hyper efficac et grand courtoisi u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21578</th>\n",
       "      <td>2</td>\n",
       "      <td>receiv gift certif birthday onli seem interest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stars                                               text\n",
       "23654      3  realli love busi cute littl store premium pet ...\n",
       "15795      4  not use compani ani busi tax advic wa refer vi...\n",
       "860        2  still understand whi post hour oper anywher ca...\n",
       "5391       3  servic amic hyper efficac et grand courtoisi u...\n",
       "21578      2  receiv gift certif birthday onli seem interest..."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPHDUwXbGFsK"
   },
   "outputs": [],
   "source": [
    "# Для дальнейшей классификации нам необходимо чтобы метки классов были целыми числами\n",
    "dataset.stars *= 10\n",
    "valid_dataset.stars *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "yX-0T85HJQJ7",
    "outputId": "c7f76195-adfd-4784-8c36-e02b193aca50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    35\n",
       "2    35\n",
       "3    35\n",
       "4    35\n",
       "5    35\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.stars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "dhB2kbFWYFtC",
    "outputId": "996a43be-8207-42f8-baea-bed922fb03e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23654    30\n",
       "15795    40\n",
       "860      20\n",
       "5391     30\n",
       "21578    20\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.stars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Непосредственно, классификация текста: используется pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p3539CaHwab"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U57CDXq5H16u"
   },
   "source": [
    "### Далее делается векторизация текста по н-граммам (из 2-ух и 3-ех слов) и строится TF-IDF на них"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем модели: Linear svc, Logistic Regression, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hs0IMvcFINQu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.2560944316140621\n"
     ]
    }
   ],
   "source": [
    "# Используем Linear SVC\n",
    "pipeline_svc = Pipeline([(\"vectorizer\", CountVectorizer(min_df=3, ngram_range=(2, 3))),\n",
    "                     (\"algo\", LinearSVC(random_state=0, tol=1e-5))])\n",
    "pipeline_svc.fit(X_train, y_train)\n",
    "print('Train accuracy', accuracy_score(pipeline_svc.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26523477 0.27043239 0.26956739 0.25837919 0.26588294]\n",
      "0.2658993360100569\n"
     ]
    }
   ],
   "source": [
    "pipeline_svc = make_pipeline(CountVectorizer(min_df=3, ngram_range=(2, 3)),\n",
    "                         TfidfTransformer(),\n",
    "                         LinearSVC(random_state=0, tol=1e-5))\n",
    "arr = cross_val_score(pipeline_svc, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(2, 3), preprocessor=None, stop_words=None,\n",
       "  ...hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.2850910957146523\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy', accuracy_score(pipeline_svc.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['year year not done done prior year weed galor miss numer area yard pay extra bug control housew get bug like thousand legger millilegg grub paid grub control long yard done',\n",
       "       'zach livingston lawn sens treat parent grass doe veri grest work friend tell veri prestig job also parent dog reason grass wa alway brown dead befor ever sinc start get treat lawn sens ha never look greener plush ha ever thank take care parent zach lawn sens',\n",
       "       'spot cute food truck check car super run classic car show want order anyth cumbersom carri sinc want free hand take pix cool car walk wa realli hungri either corn nugget menu would perfect young ladi took order wa friend talk need start tweet sinc never heard said vega streat reli social medium track mani food truck around town wait time wa le minut nugget paper tray veri hot fryer take long cool golden brown nice crunch bit insid creami kernel sweet corn noth spectacular like wa portabl wa messi get place wa happi first order look forward tri menu item track next time',\n",
       "       ...,\n",
       "       'place use realli dirti mean dirtiest mcdonald ever especi play area improv lot veri clean perhap listen complaint impress hope continu maintain cleanli final comfort celebr kid birthday',\n",
       "       'mix experi locat time servic wa decent fast coupl occas wa stuck drive thru minut unaccept mcdonald car front make mistak order extra mustard quarter pounder hard understand hey work multipl fast food chain understand question bad manag anyth els mcdonald usual',\n",
       "       'dumpi go never consist wait long drive thru dread know manag need attend hamberg univers'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "He6x80WDbaNa"
   },
   "outputs": [],
   "source": [
    "X_train = list(dataset.text.values)\n",
    "y_train = list(dataset.stars.valmakeues)\n",
    "X_valid = list(valid_dataset.text.values)\n",
    "y_valid = list(valid_dataset.stars.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"vectorizer\", CountVectorizer(min_df=3, ngram_range=(1, 3))),\n",
    "                     (\"algo\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "CaXIuo4tISOf",
    "outputId": "55eabfc7-b76d-4238-b0a4-678b19d49c2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "       ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "0tcIdj5pKmeh",
    "outputId": "dcd3eca8-c09d-41b1-8bc3-0d19b76ca3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.3193403298350825\n"
     ]
    }
   ],
   "source": [
    "# Before stemming\n",
    "print('Train accuracy', accuracy_score(pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.32974082627662304\n"
     ]
    }
   ],
   "source": [
    "# After stemming\n",
    "print('Train accuracy', accuracy_score(pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BvtRwKxlZNUi"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "MrHUyRaxbRZR",
    "outputId": "0dbd568b-ad7f-4140-9ed1-fcb51ce28128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27222777 0.27393152 0.28907227 0.27613807 0.27263632]\n",
      "0.27680118892182115\n"
     ]
    }
   ],
   "source": [
    "# After stemming\n",
    "pipeline = make_pipeline(CountVectorizer(min_df=3, ngram_range=(1, 3)),\n",
    "                         LogisticRegression())\n",
    "arr = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1tTSgnpY5O9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "OBjXGNOzZAbe",
    "outputId": "64923699-3dff-41f4-a6dc-52f5f0f4ee3c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30906274 0.31893044 0.32189257 0.31186967 0.31891368]\n",
      "0.3161338195099756\n"
     ]
    }
   ],
   "source": [
    "# Before stemming\n",
    "pipeline = make_pipeline(CountVectorizer(min_df=3, ngram_range=(1, 3)),\n",
    "                         TfidfTransformer(),\n",
    "                         LogisticRegression())\n",
    "arr = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31618382 0.31742064 0.31707927 0.31565783 0.3124062 ]\n",
      "0.3157495525712138\n"
     ]
    }
   ],
   "source": [
    "# After stemming\n",
    "pipeline = make_pipeline(CountVectorizer(min_df=3, ngram_range=(1, 3)),\n",
    "                         TfidfTransformer(),\n",
    "                         LogisticRegression())\n",
    "arr = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "amt-zQ9QZhx8",
    "outputId": "d20e6019-fe97-47bd-b95f-3ca823b3ff78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "07FUjwjBZumA",
    "outputId": "8615ef18-5da9-4ee9-97c9-8cf80af73a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.3423288355822089\n"
     ]
    }
   ],
   "source": [
    "# Before stemming\n",
    "print('Train accuracy', accuracy_score(pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.3418013856812933\n"
     ]
    }
   ],
   "source": [
    "# After stemming\n",
    "print('Train accuracy', accuracy_score(pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWbu7CLjg_58"
   },
   "source": [
    "Попробуем применить Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xG5JcciPg-oU"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VG7xONOhhFc2"
   },
   "outputs": [],
   "source": [
    "forest_pipeline = Pipeline([(\"vectorizer\", CountVectorizer(min_df=3, ngram_range=(1, 3))),\n",
    "                     (\"algo\", RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "q9psqkp4i4Mt",
    "outputId": "2db0a4c0-e64e-4a78-a75e-7a28791321c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "       ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ZljRTPbbjRku",
    "outputId": "568eeae4-188c-4b45-b8f1-d023706e0d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.2843578210894553\n"
     ]
    }
   ],
   "source": [
    "# Before stemming\n",
    "print('Train accuracy', accuracy_score(forest_pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.2734154477803439\n"
     ]
    }
   ],
   "source": [
    "# After stemming\n",
    "print('Train accuracy', accuracy_score(forest_pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.3081857839363613\n"
     ]
    }
   ],
   "source": [
    "# Попробуем изменить параметры\n",
    "forest_pipeline = Pipeline([(\"vectorizer\", CountVectorizer(min_df=3, ngram_range=(1, 3))),\n",
    "                     (\"algo\", RandomForestClassifier(n_estimators=1000))])\n",
    "forest_pipeline.fit(X_train, y_train)\n",
    "print('Train accuracy', accuracy_score(forest_pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "HbQdu8U4jcSQ",
    "outputId": "cc491782-d96d-4371-dd85-5ac9cc1d01fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25852053 0.25305173 0.25673841 0.25349108 0.25703201]\n",
      "0.25576675216095285\n"
     ]
    }
   ],
   "source": [
    "forest_pipeline = make_pipeline(CountVectorizer(min_df=3, ngram_range=(1, 2)),\n",
    "                         TfidfTransformer(),\n",
    "                         RandomForestClassifier())\n",
    "arr = cross_val_score(forest_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "8n866mRDhmzI",
    "outputId": "0bc43fe2-782b-4911-8b84-d726bce9c5a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "  ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 191,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "MtpsJLtthqxv",
    "outputId": "6d26b524-8847-4a75-8e80-9ab258b231a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.26486756621689156\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy', accuracy_score(forest_pipeline.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат линейной регресси чуть более утешающий, посему возьмем его предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.predict(list(dataset_test.text.values)) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res = pd.DataFrame({'hotel_id': pd.Series(dataset_test.hotel_id), 'stars': pd.Series(result)}, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_res.to_csv('hotels_test.csv', sep=',', index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(\"hotels_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Forecsys.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
